A transaction platform for microservices-based big data systems

Abstract:
Microservices architecture has increasingly been adopted for building distributed and scalable applications. This paper proposes a new transaction platform for microservices architecture to manage processing of big data stored in a cluster of NoSQL databases. New asynchronous protocols are designed to execute database operations as transactions, and to maintain their correctness and consistency. A prototype system has been developed that simulates London bus service across bus routes. It is evaluated through simulation experiments using big data from ‘Transport for London’ data service in order to analyze effects of transaction processing on response time and throughput in microservices architecture. The transaction platform reliably processes database operations, and enables data availability and consistency in failure-free and failure-prone environments.

Introduction:
Microservices architecture has become a popular platform for developing data-driven applications that run in complex distributed setups such as cloud, IoT, and big data systems. In microservices architecture, an application is implemented as a set of autonomous microservices representing different business components (or functionalities) working together to achieve a desired output. The aim is to provide high scalability, availability, maintainability, and decentralization of applications and data storages. Microservices can be implemented in different languages and can access data from multiple types of databases including relational (SQL) and NoSQL databases. Relational databases require data to be structured in tabular (relational) form, enforce integrity constraints, and support transactions with ACID properties. However, NoSQL databases follow different data models, provide different levels of consistency, availability, and efficiency, and do not support transactions like relational databases. They are mainly designed to process large volumes of data and generate real-time results.
In existing literature, different techniques and models have been developed for managing transactions in microservices architecture. The Saga Pattern manages local sequential transactions for updating microservices using a compensating actions approach. However, this approach does not consider read isolation, which can lead to isolation anomalies. Authors propose improving the Saga Pattern by setting a constraint that database commits only if all transactions are successful at the cache layer. CRUD operations are first performed at the memory (cache) level, and if successful, their effects are reflected at the database level. Previous work developed a framework for managing transactions considering contextual information of users and the required level of big data consistency, analyzing the impact of big data characteristics on maintaining data consistency.

Transaction management in microservices architecture involves NoSQL big databases deployed in cloud and IoT setups. A transaction comprises a series of operations (e.g., read/write) that either execute in full or not at all. If one operation fails, all operations must be rolled back to keep data in a consistent state. Managing transactions and maintaining data consistency across multiple databases is challenging due to the inherent characteristics of big data (volume, velocity, variety) and the lack of support for transactions and recovery mechanisms in NoSQL databases.

This paper designs and simulates a new two-level transaction management platform for microservices architecture that supports real-time processing of big data stored in a cluster of NoSQL key/value databases. New asynchronous protocols are designed for executing database operations as transactions to maintain data consistency. The platform processes transactional operations reliably and transparently, handling transaction failure and ensuring data availability and resilience.

A Docker containerized environment and Redis NoSQL databases are used for the design and simulation of the proposed platform. The platform is evaluated using data from ‘Transport for London’ (TfL) data service and London Bus service as a case study. Experimental results show that the transaction platform maintains data consistency and provides fair response time and throughput in both failure-free and failure-prone environments. The transaction platform ensures application correctness and data consistency, which is crucial for reliable information dissemination through various channels like display screens at bus stops, on-board screens, websites, and mobile apps.

Related work:
In microservices architecture, a transaction spans across several services and heterogeneous databases with different data models and structures. Managing transactions that guarantee data consistency and correctness involves complex design. Existing research designs general models for distributed transactions in microservices architecture. Some researchers have developed blockchain platforms to run smart contracts and execute transactions independently, achieving higher scalability and throughput. Other models, like SagaMAS, create transactions as microservices using a semi-orchestrated asynchronous model. However, it is not clear if these approaches ensure database transaction models that guarantee consistency and correctness.
Various protocols for transaction execution have been developed. The classical two-phase commit protocol (2PC) manages transactions by controlling execution in two phases but is less efficient for large-scale and highly loaded systems. The Saga pattern enhances 2PC protocol and related communication between systems but only satisfies ACD properties, not ACID, allowing partial transaction completion. Improved models, like SAGA-based Pilot-Job, and saga transaction models for long-lived transactions, provide partial solutions but may not work for NoSQL big data systems.

The transaction platform:
The proposed transaction platform for microservices-based big data systems includes different layers: client layer, application layer, storage layer, and data source layer. The platform manages data at the storage layer using transactions and microservices, adapting data before storage in specific NoSQL databases to support a variety of data storage needs.
Client Layer: Interacts between client and application layer, receiving and sending client requests.

Application Layer: Executes client requests, setting execution context for transactional or non-transactional operations, and accessing NoSQL databases through the Storage Coordinator API.

Storage Layer: Applies transaction management techniques at the data source side, managing CRUD operations according to transactional criteria, and ensuring data availability and consistency through database copies.

Data Source Layer: Represents different sources of data, sending raw data to the storage layer for processing.

Coordination in a cluster of databases applies a quorum policy to ensure data consistency, with write operations achieving success based on quorum thresholds. Fallback and rollback models handle database failures, ensuring data consistency and application correctness.

Execution protocol:
The execution protocol manages different scenarios, creating transaction contexts for each database service in a cluster, performing write/read operations, and handling fallback and rollback processes for unavailable databases.

Simulation-based evaluation:
Experiments evaluate the transaction platform using data from the London Bus service. Metrics for response time and throughput are calculated under normal, fallback, and rollback scenarios. Results show that the platform maintains data consistency and provides fair response time and throughput, even under failure-prone conditions.

Conclusion:
The proposed transaction platform and protocols manage processing of big data stored in NoSQL databases using microservices architecture. The platform is validated through a prototype system simulating London bus service, showing reliable processing of database operations and ensuring data consistency and availability in different environments. Future work may address efficiency challenges related to response time and throughput in complex distributed systems.