Title: Data Curation and Analysis Framework for Social Data: DataSynapse

Abstract
The study focuses on the increasing significance of social data analytics for organizations and governments. It presents the concept of a "Knowledge Lake," a contextualized Data Lake, which enhances the quality of insights derived from raw social data by curating and contextualizing it. The paper introduces DataSynapse, a social data curation foundry that transforms social data (e.g., tweets) into semantic items through feature extraction and cross-document coreference resolution. DataSynapse is a scalable, microservice-based architecture available on GitHub, supporting various social networks like Twitter, Facebook, GooglePlus, and LinkedIn. The system is demonstrated using a scenario involving urban social issues and government budget analysis.

Keywords
Social networks analytics
Big data analytics
Knowledge lake
Data curation
Feature engineering
Introduction
The introduction highlights the rising importance of social data analytics due to the increasing volume of data generated by social interactions. Governments and organizations use this data for various purposes, including elections, improving services, predicting activities, and enhancing security. The paper emphasizes the challenge of transforming raw social data into curated, contextualized data for effective analysis and decision-making. Data curation involves extracting, cleaning, maintaining, merging, enriching, and linking data to derive meaningful insights.

Main Contributions
Semantic-Item: Introduces the concept of a Semantic-Item for feature-based extraction and enrichment, leveraging APIs to create low-level and high-level features for data curation.

Contextualized-Item: Presents a method for linking extracted data to domain knowledge, enhancing the contextualization of data into knowledge using cross-document coreference resolution.

Scalable Algorithm: Describes a scalable algorithm for transforming social items into contextualized and curated items, incorporating customizable feature extraction.

Knowledge Lake: Defines the Knowledge Lake as a centralized repository for raw and contextualized data, facilitating big data analytics through automatic curation.

DataSynapse: Details the implementation of DataSynapse as a microservice-based architecture for social data curation, providing extensible and scalable services for extracting and enriching features from social data.

General Purpose Social Data Curation Foundry
Information-, Featurized-, and Semantic-Items
Information-Item: Represents raw social network data (e.g., tweets) with a unique identity and schema.
Featurized-Item: Describes an Information-Item with extracted features, categorized into schema-based, lexical-based, natural-language-based, time-based, location-based, and metadata-based features.
Semantic-Item: Enriches Featurized-Items with annotations, leveraging external knowledge sources for enrichment functions.
Contextualized-Item
Links extracted data to domain knowledge, forming Contextualized-Items that promote data contextualization.
Uses cross-document coreference resolution to link Semantic-Items to domain knowledge entities.
Knowledge Lake
Combines raw and contextualized data in a centralized repository.
Provides services for feature extraction, enrichment, linking, and annotation.
Supports querying through full-text search, SQL, and SPARQL, leveraging Elasticsearch and relational/NoSQL databases.
Microservice-Based Architecture
Describes DataSynapse's architecture, which supports large-scale data curation through microservices.
Leverages Apache UIMA for reusable and composable micro-services, enabling scalable data processing pipelines.
Motivating Scenario and Experiments
Scenario: Urban Social Issues and Government Budget Analysis
Demonstrates the application of DataSynapse in analyzing Twitter data related to the Australian Government's budget and urban social issues.
Highlights the three-step data curation pipeline: extraction, contextualization, and analysis.
Experiments
System Setup: Details the experimental setup using Amazon EC2 instances.
Dataset: Describes the collection of 15 million tweets related to the Australian Government's budget.
Evaluation: Assesses DataSynapse's effectiveness (precision, recall, F-measure) and efficiency (execution time) in linking semantic-items with domain knowledge.
Conclusion
DataSynapse significantly enhances the quality of extracted knowledge compared to classical curation pipelines. The framework's microservice-based architecture and feature-based extraction techniques improve the precision and recall of data curation tasks. Future work involves refining the model, enhancing precision and recall, and developing novel techniques for intelligent narrative discovery and data summarization.