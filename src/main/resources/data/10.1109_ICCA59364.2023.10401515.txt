From Models to Microservices: Easily Operationalizing Machine Learning Models
Deven Panchal
AT&T
Middletown, NJ, USA
devenrpanchal@gmail.com

Isilay Baran
AT&T
Middletown, NJ, USA
ib6391@att.com

Dan Musgrove
AT&T
Middletown, NJ, USA
dm4812@att.com

David Lu
AT&T
Dallas, TX, USA
dl1971@att.com

Abstract
Although Machine Learning and Deep Learning have advanced significantly in their ability to perform supervised, unsupervised and reinforcement learning tasks quite well, integrating them into applications for which they are meant to provide intelligence is not as seamless as it should be. There are many reasons for this – primary being that the kind of skills needed to understand the business need, understand the data, develop models, develop applications, and integrate models with applications are different and it is very difficult for one person or just a group of application developers or just a group of data scientists to have all these skills. This makes it challenging to productionalize the developed ML models fast or at all in order to experiment with them further. This paper demonstrates how certain components of the Acumos AI platform project can be used to take models developed using H2o, Java, Spark to production by deploying them as microservices, automatically. The same concept can be (and has been extended by Acumos) to Python, R and ONNX models. What this enables is - multiple heterogeneous models written by different developers or different teams or different organizations in different languages and frameworks becoming functioning microservices that would provide intelligent APIs to the business application in question. These models can then be easily shared with different individuals and organizations and operationalized easily. Using Acumos, these microservices can be deployed such that they also communicate and co-ordinate with each other to do much more complex tasks. We will talk about the 5G Network Slicing usecase, create an ML model for 5G Network Slicing and use certain Acumos components to make it shareable and operationalize it as a predicting microservice.

Index Terms
Acumos, Machine Learning, MLOps, Platform, Microservices, 5G, Network Slicing, eMBB, mMTC, URLLC, Open Source, AI4EU

I. BACKGROUND, PROBLEMS, AND INTRODUCTION TO ACUMOS
Machine Learning, Deep Learning and other AI techniques have gained increased attention across different industries and are being increasingly employed for a variety of tasks. The reason for this rise in usage can be explained by a multitude of factors that include the availability of cheap and plentiful computing resources that the ML/DL tasks require, the availability and accessibility of the many ML/DL/AI tools, libraries and frameworks, the promise that ML/AI has shown in being able to solve complex problems with a greater accuracy than it has ever been possible, and the large-scale interest it has hence generated – be it business interest or research interest or career wise. All these factors along with the fact that these AI/ML techniques are saving companies money or helping bring in more revenue, are helping push AI forward every day. There are however some issues surrounding AI that remain unexplored or less explored. One such issue is that of AI productionalization due to various reasons. More work needs to be done to make AI models and services usable to people directly, safely and as inexpensively as possible.

The Acumos AI project aims to do just that. The broader Acumos AI project has various different components that can help build, share, deploy and reuse AI applications. It helps to run an out of the box AI environment that can help make AI services increasingly accessible. The AI4EU Experiments distribution of Acumos is hosted at AI4EU Experiments. But you can certainly stand up your own instance of Acumos.

Business domain knowledge and requirements gathering, data science and machine learning modelling, development of a data engineering pipeline, development of business applications, integration of ML models with business applications require varied skillsets that one person, or a small not-for-profit organization or a small company, or a small team in a company may not have. Even if they do have these skills, it has been difficult for these skillsets and people to co-ordinate and so data scientists, ML engineers, software developers, data engineers, DevOps Engineers end up working in silos to make suboptimal decisions along the way. The situation is further aggravated when all the different teams need to settle on a common technology stack and end-up having very steep learning curves and wasted time. Some of the components we describe below solve all these problems and effectively allow ML engineers, software developers to focus on their own core-competencies while the Acumos components do most of the heavy lifting to allow sharing of the models, and productionalization and free usage of the models. This can help save significant amounts of both time and money. Acumos can handle models written in different languages (Python, R, Java) and various toolkits/frameworks like scikit-learn, keras, H2o, Spark, ONNX etc.

II. USING THE ACUMOS JAVA CLIENT AND ACUMOS MODEL RUNNERS FOR H2O, JAVA, SPARK MODELS
The Acumos Java client and the Acumos Model Runners for H2o, Java, Spark based models (there are model runners for Python, R and ONNX based models too), we will see, will allow the data scientists and software engineers to focus on their core-competencies. When using these tools, the data scientist or the ML Engineers would first start off by doing data curation, data cleaning, data processing and visualization and then finally building an ML/DL model in H2o or Java or Spark (Python, R, ONNX are also possible via other model runners). The ML modeler would then have to simply export his model to a mojo zip file format (if he used H2o) or a jar file (if he used Java or Spark). The ML modeler would then download the latest version of the Acumos Java client artifact from the Acumos Nexus repository and also download the latest version of the Acumos Model Runner artifact from the Acumos Nexus repository. He would then run the Java client tool by supplying it the previously exported model and the downloaded Acumos Model Runner artifact to output a bunch of different artifacts - metadata.json, a .proto file and a modelpackage.zip file. This process also creates a common Acumos wrapper around the ML model and packages it as a microservice that exposes certain APIs. Now, the ML modeler can manually upload these generated artifacts to the Acumos marketplace GUI/website - which is known as web-based onboarding or he could have alternatively passed in some extra parameters when running the Java client tool. In this case, the Java client tool would have done the onboarding for the user. This is known as CLI-based onboarding.

To show a little low-level implementation so that the user is better able to appreciate how the Acumos onboarding and microservice generation works, we will quickly talk about the onboarding server component. In both, web-based onboarding and CLI-based onboarding, the modeler is essentially onboarding artifacts resulting from the Java client run to in fact a REST API that the onboarding server exposes. Once it accepts the artifacts on the REST API, it creates a docker image for the model microservice, and pushes the docker image to Acumos Nexus Docker registry. It then uses Acumos common data microservices API to create a solution and store the model and the metadata to the Acumos Nexus artifact repository.

Following this, the onboarding server performs a model validation workflow. Once the onboarding of the models to the Acumos Marketplace is complete, the ML model microservice can then be shared with your team or can be published to the company marketplace or published to the public marketplace or exported and deployed to any cloud environment like AWS, Azure, GCP or even Kubernetes or even just run locally as single docker container on your local machine. The Acumos marketplace also allows you to track how many times the model has been downloaded, what others are saying about the model (model pages have a comments section) or even delete the model if that is what you wish to do.

III. SOME API ENDPOINTS EXPOSED BY THE MICROSERVICE
The model microservice provides many API endpoints to do predictions and more with csv or json data. The model microservice itself allows you to change the microservice configuration on the fly or allows you to replace or completely change the underlying ML model effectively making it a microservice that does something completely different from the original microservice all without even bringing down the service or the underlying infrastructure. This microservice/model can be composed with other compatible models to create a complex solution in the Acumos Design studio. This can allow a user to perform automatic microservice chaining to accomplish bigger tasks that individual ML models/microservices may not be able to perform.

IV. CREATING, DEPLOYING AND USING A 5G DEEP LEARNING BASED NETWORK SLICING MICROSERVICE WITH THE HELP OF ACUMOS
We will demonstrate the creation, deployment as a microservice and usage of a 5G Network Slicing Deep Learning model (it could also have been a Machine Learning model created using any of the popular frameworks) using the Acumos components/tools we talked about earlier. 5G networks have very high standards for data rates, latency, user experience, spectrum efficiency, mobility, connection density, capacity, network energy efficiency, etc. Accordingly, 5G networks will have to consider how to be able to provide great customer experiences across service types/ traffic types while being cost-efficient for the operator. 5G Network slicing promises this by segmenting users and traffic based on all the aforementioned requirements and allocating virtual network slices to them. It enables new use cases that can help service flexibility, service agility, security and optimized resource management. Further, in 5G there can be potentially many slice templates based on varying SLA’s and requirements. Hence it becomes difficult for the operator to select the slice manually. As described, an intent-driven networking based smart solution could use the 5G Network Slicing to select the target slice automatically and accurately for e.g., in a solution implemented in the Open Network Automation Platform (ONAP). For the current model, the dataset we used includes popular network and device KPI’s like device type, day of the week, time of the day, QCI, packet loss rate and delay budget etc. which can be easily compiled by analyzing the packet capture files. Based on these inputs, we allocate a slice to each of these connections. The slices allowed for the current model are: eMBB slice - that stands for enhanced Mobile Broad Band and is used for high throughput mobile communications and internet. mMTC slice - that stands for massive Machine Type Communication and is used for low throughput but high density IoT and MTM communications. URLLC slice - that stands for Ultra Reliable Low Latency Communication and is used for reliable low latency Automotive, Medical and Industry 4.0 type communications. We use H2o’s python interface to create a Deep Learning based model. We split the original dataset into 70% training, 15% validation and 15% test sets, and create a model with an input layer of 28 neurons, and 2 hidden layers, with 18 and 9 neurons, followed by a softmax layer with 3 units to classify traffic communication into one of the 3 slices. With this configuration, we are able to do a pretty decent job at classifying the traffic well into one of these 3 slices i.e the eMBB slice, mMTC slice or URLLC slice.

We create a similar model on the same dataset using H2o’s Flow GUI to show that you can create the model however you like and, in the toolkit/framework you are comfortable with. We download the model as MOJO zip file, download the H2o gen model jar, and download the Acumos Java client from the Acumos Nexus Repository and download the Acumos Model runner from the Acumos Nexus Repository.

V. NEXT STEPS AND CONCLUSION
We then follow the easy steps to run the Acumos Java client to onboard the Network slicing model to Acumos. At this point, the Acumos Model Runner has wrapped the model in an Acumos-style wrapper that makes it a containerized microservice offering a prediction API along with many useful APIs to manage other aspects of the model. You can do much more with an onboarded model. You can manage and share these models/microservices with individuals, teams, organizations, and sell them to different companies and entities through Acumos Federation and Acumos Licensing. This ease of sharing, experimentation and integration helps achieve significant cost savings when compared to using readymade cloud ML offerings that charge per API call and allows ML modelers and software developers to focus on their core competencies, prevent suboptimal decision making due to any silos and help them partner effectively to take language ML models to production very easily. Accordingly, our Network slicing model can be further deployed to and managed, say, using Kubernetes on most popular cloud platforms like AWS, Azure and GCP right from within Acumos. We have been highlighting the fact that one purpose of Acumos components is to make tying of language agnostic Acumos ML services possible. We have seen how Acumos makes it possible by actually wrapping the heterogeneous models with a docker microservice wrapper with many functionalities accessible via the microservice’s APIs so different applications built by different teams using different tech stacks can co-exist harmoniously. The ONNX project also allows you to convert models from one framework to another, and has this support for many popular frameworks. Acumos recognizes this and also allows onboarding ONNX models to its marketplace to convert ONNX models to microservices. Acumos also offers components to operationalize Python (sklearn, Keras, Tensorflow), R based models. Additional Acumos components like the Acumos Design Studio can also help you create composite solutions by tying together compatible models. The composite solution can also be deployed through Acumos and can help do much more complex tasks than what individual models can do themselves. Another point to note is - that while we have talked about and used Acumos Java client and the Acumos Model Runner for Machine Learning models, the models in fact may be any kinds of models - not necessarily models doing tasks that would involve Machine Learning or Deep Learning or AI. For e.g., we can use the same Java client and Model Runner to take financial models like the Black-Scholes option pricing model written in Java or models in economics, population studies, clinical studies etc. and create predicting microservices out of them. The tools we discussed will help you operationalize your code in the exact same way we have operationalized the ML models.