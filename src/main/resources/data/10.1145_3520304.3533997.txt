Facilitating the Hybridization of Parallel Evolutionary Algorithms in Cluster Computing Environments
Hatem Khalloof, Sergen Ciftci, Shadi Shahoud, Clemens Duepmeier, Kevin Foerderer, Veit Hagenmeyer
Karlsruhe Institute of Technology, IAI, Karlsruhe, Germany
ABSTRACT

Evolutionary Algorithms (EAs) need domain-specific adaptations for achieving better results, tend to converge to suboptimal solutions, and are computationally expensive when applied to complex and large-scale optimization problems. Hybridizing EAs with other algorithms and methods and parallelizing them in cluster computing environments represent essential solutions. In this paper, a new software solution for supporting the hybridizations of parallel EAs is proposed. Unlike other software solutions for hybridizing EAs, the proposed software solution provides a flexible, generic, and scalable mechanism for integrating any algorithmic approach like a Machine Learning (ML) algorithm to seed the initial population of parallel EAs. It is designed based on three modern software technologies: microservices, container virtualization, and the publish/subscribe messaging paradigm. The applicability and generality of the presented software solution are tested by hybridizing the General Learning Evolutionary Algorithm and Method (GLEAM) with ML techniques for solving the problem of scheduling Distributed Energy Resources (DERs). The benchmarking tests are performed in a cluster computing environment. The obtained results show that the new software solution represents a successful approach to facilitate the hybridization of parallel EAs, paving the road for future applications of EAs in several domains.

Keywords: Hybrid Evolutionary Algorithms; Parallel Evolutionary Algorithms; Global Model; Microservice; Virtualization; Container; Scheduling Distributed Energy Resources; Parallel Computing; Scalability

1. INTRODUCTION
For solving complex and large-scale optimization problems such as scheduling Distributed Energy Resources (DERs) utilizing renewable energy generation, conventional optimization techniques, such as exact and heuristic methods, provide either very poor solutions or no solutions. Population-based metaheuristics like Evolutionary Algorithms (EAs) can find good local optima or even global ones for such problems. However, EAs usually require a large number of fitness evaluations, which are time-consuming. EAs also suffer from the limitation of not using domain-specific knowledge and the risk of premature convergence. To overcome these drawbacks, parallelizing EAs by exploiting their implicit parallelism and hybridizing them with other algorithms and methods are two main solutions. Parallelization can drastically reduce the computation time since the computational effort is distributed across multiple machines. The parallel classification schema proposed by Cantú-Paz introduces the most important and used parallelization models for EAs, distinguishing between two main parallel calculation approaches: parallelizing the evaluation step and structuring the population to apply the genetic operators in parallel. This results in three basic parallel models: the Global Model, the Coarse-Grained Model (Island Model), and the Fine-Grained Model.

EAs must adhere to the "No Free Lunch Theorem," which states that a given optimization algorithm cannot be applied to different optimization problems with equal performance without showing some kind of performance problems or having problems finding an appropriate solution. Hybridizing EAs, i.e., combining them with one or multiple other algorithms and methods to better adapt them to the precise problem setting, opens new perspectives for applying EAs in a wide area of applications, enhances the solution quality, and reduces the computational time to arrive at a proper solution. Each step of an EA can be hybridized, such as generating the initial population, estimating the fitness function, and applying the genetic operators and selection policies.

Many frameworks involving several software technologies to hybridize sequential EAs or parallel EAs are proposed. The monolithic architecture is the classic approach followed to develop these frameworks, where EAs and all functionalities related to parallelization and hybridization are maintained in a single codebase. This hinders the scalability of the system on a cluster and complicates its reusability and maintainability since there are no hard boundaries between the functionalities. In contrast, microservices architecture provides the flexibility to scale the execution of EAs on cluster or cloud and the ability to implement, maintain, and deploy each microservice independently.

In this paper, we propose a new microservice-based software solution for facilitating the process of seeding the initial population of a parallel EA. It is designed to be generic, modular, and flexible so that any adequate ML algorithm or model for seeding the initial population of an EA can be plugged in. The applicability of the proposed approach is evaluated by hybridizing the parallel General Learning Evolutionary Algorithm and Method (EA GLEAM) with two ML approaches: an unsupervised technique (clustering) and a supervised technique (Sequence to Sequence (Seq2Seq) Long Short-Term Memory (LSTM) models with multiple-output-layers). Both approaches assist the EA GLEAM by generating the initial population for solving the problem of scheduling DERs. The proposed approach is deployed in a cluster with four nodes, 60 cores, and 196 GB of RAM. The obtained results show that the presented software design is an applicable approach for seeding the initial population of a parallel EA using different ML techniques in cluster computing environments.

3. MICROSERVICE AND CONTAINER-BASED ARCHITECTURE FOR HYBRIDIZATION OF EAS WITH ML ALGORITHMS
We introduce a new microservice-based solution to help EA developers by combining an already developed EA with any ML algorithm or model for generating the initial population. The present software solution extends the conceptual microservice-based architecture for parallelizing EAs introduced by Khalloof et al., depicted in Figure 1. Besides microservices, two lightweight technologies—container virtualization and the publish/subscribe messaging paradigm—are exploited for developing a fully automated and highly scalable solution. Each service can be scaled and developed independently. The User-Interface (UI) Tier and the Cluster Tier are the main two tiers of the framework. The UI Tier is dedicated to user interactions, such as configuring, starting, stopping, and monitoring one or multiple optimization tasks. The backend (Cluster Tier) is divided into two layers: the Container Layer and the Data Layer. The Container Layer contains all services used to perform the optimization task, e.g., the EA Services, services that manage and control the parallel execution of such EA, and other services required by the studied use case. Each service in the container environment is realized as a microservice and encapsulated in a software container for runtime automation. The Data Layer provides two types of storage: persistent storage and temporary storage. The backend is accessed via the UI Tier using simple web-based APIs.

The generality, modularity, flexibility, and scalability of this architecture enable an easy integration of any new functionality as a new microservice in the Container Layer. To this end, a microservice called Support-and-Learning Service (S&L Service) is introduced. It provides the ability to plug in any ML algorithm and model to assist EAs by generating the initial population. All tasks related to the process of assisting EAs by generating a more adequate initial population are carried out by this service. One popular method for enhancing EAs is to integrate domain-specific knowledge in the evolutionary process. Generally, a generic EA does not integrate such knowledge into the evolutionary process and for each new problem they start from scratch. The S&L Service allows the integration of ML algorithms to perform the task of learning by extracting latent patterns from domain-specific knowledge and already found solutions of an optimization problem for guiding the search process of the EAs in solving a new similar optimization problem.

A high decoupling degree among the microservices is achieved by using the publish/subscribe messaging paradigm for establishing communication between the S&L Service and other services. This communication paradigm guarantees an efficient and reliable data exchange between the S&L Service and others and enables the S&L Service to assist any already existing EA by generating the initial population. The S&L Service provides two publish/subscribe channels: "jobQueue" and "chromosomeAsSeeds." These channels support the communication between the S&L Service and EA Service. The "jobQueue" channel is used to publish the job requests related to generating a part of the initial population, while the "chromosomeAsSeeds" channel is used by the S&L Service to publish the results of one job.

The proposed unsupervised approach trains a clustering algorithm with domain-specific knowledge that corresponds to the solutions obtained from the previous runs of an EA. Then, it groups similar domain-specific knowledge into clusters. When a new optimization problem is considered, the clustering model assigns the new unseen domain-specific knowledge to the closest cluster. Afterwards, one or multiple potential similar solutions corresponding to the selected cluster are returned as seeds. The supervised approach trains a ML algorithm to generate potential solutions by making predictions on new domain-specific knowledge.

To achieve that, the domain-specific knowledge and the prior solutions are combined to form a dataset where the features are represented by the domain-specific knowledge and the labels by the prior solutions. Each job request published in the "jobQueue" channel defines three input parameters: "mode," "featureType," and "amountOfChromosomes." The "mode" parameter selects one of the proposed ML approaches to hybridize an EA, the "featureType" parameter selects the features from the "Prior Knowledge Repository" for training and testing the selected ML algorithm, and the "amountOfChromosomes" parameter defines the requested number of solutions (chromosomes) to be returned from the S&L Service and seeded into the initial population.

4. EVALUATION
The applicability of the proposed approach for seeding the initial population using unsupervised and supervised learning approaches is tested and evaluated. The use case for scheduling DERs introduced in previous works is used as an evaluation scenario, considering 50 DERs and a load forming a microgrid. The proposed scheduling plan must fulfill two main conditions: covering the requested power from the consumer at each time interval and doing so at minimal billing cost. These conditions form a nonconvex mixed-integer nonlinear optimization problem. The weighted sum is used to combine the results of the criteria into a fitness value representing the quality of the proposed solution. The greater the values, the better the solution.

Scheduling DERs is an NP-hard optimization problem that requires lots of computational power, making it an adequate problem for our evaluation. Using parallel EAs for finding the proper schedule reduces the required computation time. Hybridizing EAs with ML to initialize the initial population can also reduce the required runtime to reach a specific solution quality.

4.1 EA-based Scheduling

The proposed approach can support any EA to create scheduling plans for the considered use case. For this evaluation, we choose the EA GLEAM since it offers the ability to seed the initial population from previous computations or even from external services. For scheduling DERs with the EA GLEAM, we use the coding schema presented in Figure 4, where each gene consists of four specifications: unit ID, start time, duration, and power fraction. The unit ID refers to the DER ID, the start time and duration parameters specify when and how long the power fraction is valid for this DER, and the power fraction parameter determines the amount of energy taken from this DER.

4.2 Data Preprocessing

The domain-specific knowledge for scheduling DERs can be characterized by features such as the load profiles of customers, the energy generation from each DER, and the weather conditions. However, only energy generation from DERs and load profile of customers are considered. For this evaluation, we use the Solar Home Electricity dataset provided by Ausgrid, which contains consumption and generation data for 300 households with PV systems. After preprocessing the data, we create a training dataset where the computed solutions (scheduling plans) serve as labels, and the corresponding domain-specific knowledge (consumption and generation) is used as features.

For testing the proposed approaches, domain-specific knowledge of the same 50 DERs and the load profiles of the same household for the second year of the data are considered. Based on their similarity to days in the training dataset, two load profiles are selected for testing: a complex load profile and a simple load profile.

4.3 Unsupervised Approach for Scheduling DERs: Clustering-based Approach

The goal of the clustering-based approach is to cluster prior scheduling plans into clusters based on the similarity of their corresponding domain-specific knowledge. The generation per hour of each DER and the consumption per hour of the considered customer are used by a clustering algorithm to group similar scheduling plans from the prior solutions repository into a cluster. For creating a new 24-hours day ahead scheduling plan for the same customer, the clustering algorithm finds similar scheduling plans related to the cluster in which the load profile of the customer and the generated power from the 50 DERs are clustered for seeding the initial population of the EA GLEAM.

The generic design of the S&L Service enables the usage of different clustering algorithms like KMeans, Affinity Propagation, Agglomerative Clustering, and DBSCAN. In this work, we focus on using KMeans. We train the KMeans algorithm based on three feature set combinations: consumption, generation, and consumption-generation. We use AutoEncoders (AEs) to reduce the dimension of the feature spaces. KMeans achieves the best results using the encoded features and ten clusters.

4.4 Supervised Approach for Scheduling DERs: Long Short-Term Memory Neural Networks-based Approach

The selected ML algorithm for the supervised approach has to predict a dynamic number of genes and multiple outputs for each gene to create a chromosome. Sequence-to-sequence Long Short-Term Memory networks (seq2seq LSTMs) are suitable for this task. The proposed seq2seq LSTM model takes the consumption of the customer and the generation of 50 DERs as input and outputs a sequence of genes that collectively represent a chromosome. The encoder captures the context of the input, and the decoder interprets and extracts the context to produce a decoded sequence, which is then mapped to the output format.

To predict the four independent variables of each gene, we apply one-hot-encoding. The LSTM model has four output layers, each predicting one variable of a gene. We train four seq2seq LSTM models with one hidden layer and 32 neurons for the encoder and decoder.

4.5 Deployment on a Cluster

The S&L Service with the clustering-based and LSTM-based approaches is integrated into the framework developed for scheduling DERs using parallelized EAs in a cluster computing environment. A PostgreSQL database stores the prior solutions, and an InfluxDB stores the domain-specific knowledge. The framework is deployed on a cluster with four computing nodes. A modern software environment based on container automation technology, Docker, and Kubernetes ensures a seamless deployment of the microservices on the cluster.

4.6 Experimental Setup and Results

We assess the convergence speed of the EA GLEAM by measuring how fast it converges to a solution with a predefined fitness value. The EA GLEAM is set to stop evolution after 200 generations, and population sizes are varied between 20 and 200. We define two fitness values as termination criteria: 87% for the simple load profile and 51% for the complex load profile. The seeding rate of the initial population is set to 10% of the population size. The results indicate that hybridizing the EA GLEAM with the proposed ML-based approaches improves the convergence speed compared to the random seeding.

5. CONCLUSION AND FUTURE WORK
In this paper, a new microservice-based solution for seeding the initial population of a parallel EA in cluster computing environments is introduced. The solution is modular, extendable, flexible, generic, and scalable. The applicability of the solution is demonstrated by integrating unsupervised and supervised hybridization approaches for seeding the initial population of EAs. The evaluation using the use case of scheduling DERs shows an improvement in convergence speed. Future work includes utilizing other ML techniques for hybridizing EAs, using larger datasets for training, performing more experiments, and conducting in-depth studies for assessing the performance of hybrid EAs in general.

