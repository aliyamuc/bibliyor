Abstract
The complexity of building, deploying, and managing cross-organizational enterprise computing services with self-service, security, and quality assurances has been increasing exponentially in the era of hybrid multiclouds. AI-accelerated material discovery capabilities, for example, are desirable for enterprise application users to consume through business API services with assurance of satisfactory nonfunctional properties, e.g., enterprise-compliant self-service management of sharable sensitive data and machine learning capabilities at Internet scale. This paper presents a composable microservices based approach to creating and continuously improving enterprise computing services. Moreover, it elaborates on several key architecture design decisions for Navarch, a composable enterprise microservices fabric that facilitates consuming, managing, and composing enterprise API services. Under the service management model of individual administration, every Navarch microservice is a managed composable API service that can be provided by an internal organization, an enterprise partner, or a public service provider. This paper also illustrates a Navarch-enabled systematic and efficient approach to transforming an AI-accelerated material discovery tool into secure, scalable, and composable enterprise microservices. Performance of the microservices can be continuously improved by exploiting advanced heterogeneous microservice hosting infrastructures. Factual comparative performance analyses are provided before the paper concludes with future work.

Keywords: microservices architecture, composable enterprise services, API fabric, material discovery

Introduction
The complexity of building, deploying, and managing cross-organizational enterprise application services with self-service, security, and quality assurances has been increasing exponentially in the era of hybrid multiclouds. Conventional server-storage-network based approaches to designing and/or realizing distributed enterprise computing services have become inappropriate when modern computing technologies are employed, e.g., CAP Theorem, containers, serverless computing, deep learning, DevOps, etc. Lack of first-class concept of service in the client/server computing caused various server consumability issues for the clients in the past. Similarly, due to the lack of first-class concept of composable microservice, conventional services computing approaches do not provide a good perspective on how to decompose an enterprise-compliant computing service into a collection of composable and manageable API services at business level and IT level.

This paper proposes a coherent set of service architecture design principles under which composable microservices are first-class citizens, formalizing individually administered composable API services in terms of assured properties that are measurable, validatable, and verifiable at their respective API service endpoints. Example composable microservices are a commercial event streaming service with an availability service level agreement (SLA), an enterprise API gateway service with availability operations level agreement (OLA), and a RESTful data analytics service with a GDPR (General Data Protection Regulation) compliance indicator.

This paper also presents key architecture design decisions for the Navarch composable enterprise microservices fabric, which is a reference realization of our microservices-oriented architecture. Navarch facilitates consuming, managing, and composing public/private enterprise microservices for API-based applications. Complementary to enterprise API gateway microservices (which can be solutioned using on-shelf products), Navarch autonomically handles RESTful microservice requests at the application level (with support for asynchronous fulfillment) and transparently performs data transfer/transformation across heterogeneous microservice hosting zones (in terms of security, privacy, availability, performance, etc.) in a hybrid multicloud environment.

Navarch now provides six REST API invocation contexts for its API clients: development, test, or run for external or internal subscribers, respectively. From a service provider’s viewpoint, a Navarch business microservice request can be fulfilled by a group of other business and/or IT microservices. Every Navarch API request is fulfilled in the context of a team/project-based subscription, determined by the API subscriber id and API key credentials in use. The API keys are shareable by subscription. Subscription-based consumption authorization, entitlement, and billing of Navarch capabilities are done in a policy-based manner. Self-service subscription, subscriber, and API key lifecycle management capabilities (including create, read, update, and delete keys) are provided.

Several motifs of composite heterogeneous microservices have been realized in Navarch with applications in the areas of anti-money laundering, financial forecasting, temporal geospatial analytics, etc. This paper illustrates Navarch’s systematic and efficient approach to transforming a Python application into composable enterprise microservices via the AMD (Accelerated Material Discovery) tool. AMD’s differentiating functional capabilities can be consumed through the Internet via Jupyter notebook servers before they are added to the Navarch fabric. The transformation effort enhanced AMD consumability with many nonfunctional properties, e.g., assurance of enterprise-compliant self-service management of sharable sensitive data and heterogeneous machine learning capabilities at Internet scale. The enhancement was made without changing the AMD Python package and removed Jupyter server dependency. The composed third-party capabilities include business support services (BSS), operations support services (OSS), application-level mediation, etc.

Novel research contributions of this paper are: (1) a coherent set of microservices architecture design principles under which composable microservice is a first-class abstraction, facilitating composing existing individually administered microservices in large with nonfunctional property assurances (and separating related issues from those about microservice-specific system realization and management); (2) a credible realization of a composable enterprise microservices fabric that recognizes business and IT microservices as well as facilitates consuming, managing, and composing external and/or internal enterprise API services in a hybrid multicloud environment; (3) a creditable microservices-based reference realization of a shareable-API-key based unified mechanism for API service invocation authentication, authorization, and entitlement per the subscription in use; and (4) a credible composable enterprise microservices fabric based systematic, incremental, and efficient approach to transforming an application into composable enterprise microservices.

Microservices Architecture Design Principles
This section first briefs a list of architecture design work products that are key to the success of realizing enterprise computing services. It then shows several role-based use cases for enterprise API services. Finally, it presents a list of key design principles for composable enterprise microservices.

Architecture Design Work Products
It is nontrivial to create an enterprise application service from scratch. Below is a partial list of important questions that need to be answered in the architecture design work products for an enterprise service:

What are the use cases?
What are dependent human and/or system actors?
What are fundamental architecture building blocks?
What tradeoffs are made in architecture design?
How is the service application structured?
What is the operational model of the service?
How cross-organization workflows are realized?
How are nonfunctional requirements fulfilled?
How to assure security, privacy, and compliance?
Answers to those questions for a built-from-scratch enterprise service system (e.g., an enterprise web portal) are expected to include, among other code and documentation artifacts, component deployment diagrams and system configuration details for servers, storage, network, firewalls, middleware, etc. The effort required is much higher than that of deploying a proof-of-concept web application server for a small internal team, not to mention the knowledge and skills required to answer those questions well. Necessary enterprise compliant integration with existing enterprise business and IT management processes (e.g., account onboarding process with denied party list checking) can take several person-years to complete, followed by spending recurring expenses on service operations management.

Enterprise Microservices Use Cases
Business Administrator defines service offerings (as a service provider) or owns service subscriptions (in charge of service usage payment for the service client team/project). A subscription owner decides on subscriber inclusion and subscriber role assignment, though she/he may not need to consume microservice capabilities.

Application Developer creates service API-based client applications. Shareable API keys used for invoking a specific service can be accessed and/or managed via enterprise microservice catalogs (e.g., IBM APIe on the Internet, BlueAPI on IBM intranet, etc.). The client application must be configured with authorized API keys for the target microservices before it invokes their APIs, though the key credentials (e.g., client secrets in API Connect solutions) should not be included in the source code repository. In Navarch, a subscriber id, optionally with the id’s password, is also required when such an invocation is made to securely support subscription-based authorization and entitlement.

Data Scientist consumes various remote microservice capabilities (sequentially or in parallel) via an application (e.g., a Jupyter notebook), which can be configured with several microservice API keys. The application in use, either running locally or remotely, need not be the only provider for those capabilities. Version control microservices (e.g., GitHub Enterprise) can be used to maintain application artifacts, e.g., Jupyter notebooks.

Service Developer publishes service APIs in enterprise internal and/or external microservice catalogs for the service offerings registered at those catalogs by her/his Business Administrator. DevOps technologies would be employed to optimize the continuous service improvement process in use, including the change management process for microservice deployment credentials.

Architecture Design Principles
Recognizing the increasing complexity of delivering quality-assured enterprise computing services, we define our microservice-oriented architecture (MOA) in terms of a list of architecture design principles:

Individual administration: Every microservice has its own DevOps and operations management processes so that functional capabilities and nonfunctional properties can be defined, measured, and managed at its service endpoint, e.g., a REST API endpoint. Number of servers used for implementing a specific microservice endpoint can change dynamically, e.g., a Kubernetes microservice with an autoscaling policy. A taxonomy can be used to annotate the endpoints consistently with the goals of maximizing business value of the deployed microservices. Compliance rules, which are typically viewed as business control policies, can be directly associated with each individually administered microservice.
Client-facing separation of control and data planes: From the service client’s viewpoint, the microservice endpoint used for submitting service requests can be different from that for transferring input/output data, which can be large and result in significant operations management cost and serviceability issues. Similar to the B-ISDN protocol reference model, an API interface to the client can be composed of several microservices, e.g., some for control, and some for data transfer. The request can be fulfilled synchronously or asynchronously.
Eventual consistency of microservice states: Many IT system management challenges in the past were caused by assuring state consistency across the whole system all the time (e.g., employing a configuration management database, CMDB, as the authoritative source of system configuration states). Given the wide adoption of eventual consistency in NoSQL databases and automated configuration management, it would be impractical to demand state consistency across all microservices in use.
Individually administered composite microservices: Every composite microservice must also be administered individually. When composing microservices, the creator must assure manageability of the consumption relations between the composite microservice and the constituent microservices such that the composite microservice can be consumed by the target client applications as one individually administered microservice. When necessary compliance metadata is available for dependent microservices, ascertaining compliance of a composite microservice can be done effectively and automatically per institutionalized compliance checks.
Navarch Design and Realization
Navarch is a composable enterprise microservices fabric. It is a reference realization of our microservices architecture for enterprises.

Business and IT Microservices
Navarch microservices fabric comprises two kinds of microservices: business microservices and IT microservices. Business microservices, listed in paid API service catalogs, provide application capabilities with contractual service consumption authorization policy, pricing schedule, and quality assurance terms. IT microservices are not paid offerings and do not have BSS capabilities, e.g., metering, rating, accounting, etc. Sample IT microservices are IAM, monitoring and event management, logging, organizational API service registries, and departmental RESTful services. The Navarch microservices fabric facilitates creating and managing a business microservice by composing several other business and/or IT microservices in terms of regulation, standards, and business requirements, e.g., GDPR, OpenAPI, and enterprise compliance rules. Major business values of this enterprise microservices composition approach are significant reduction in time-to-value, in noncompliance risk, and in development and operations management cost.

RESTful Microservices and Temporary Objects
Most Navarch client-facing API services are RESTful, though dependent microservices can be consumed through non-RESTful APIs, e.g., Kafka pub/sub messaging API. They operate mainly in the client-facing control plane.

Companion data services are available in Navarch’s client-facing data plane to facilitate subscription-based data upload, download, and sharing. Navarch provides a RESTful microservice that enables its client applications to create, read, and delete temporary object resources, each of which has a lifespan and two signed URLs: one for uploading and updating object contents, and the other for downloading object contents. The REST resources can be shared among the client applications by subscription, though sharing of the temporary URLs is beyond the scope of Navarch.

REST Resource Models and Subscription-Based Sharing
Navarch REST resource models include one set of root resource collections and many sets of application-specific ones, each of which is an API component in Navarch terms.

As part of Navarch’s REST API governance rules, the resource path namespace is structured hierarchically with [/] as the REST base path prefix for root resources and [/{app}] as the base path prefix for component {app}, which can be “amd”, “fss/aml”, “util/kb”, etc. Depending upon external/internal REST API service product definitions, a specific subscription can include authorized access to the root component with zero or more other API components.

All the REST resources are sharable by subscription. Moreover, security credentials (e.g., access key for an S3 bucket) can be reviewed only by the creators, though credential-embedding resources can be referenced by unique ids by other subscribers of the same subscription.

Besides [/tempobjs] for temporary objects and [/s3keys] for S3 keys, other root resources regard, respectively, API invocation context ([/settings]), data transfer and sharing [/collections], management of asynchronously executed request fulfillment jobs [/jobs], subscription variables [/variables], etc. [/noop] is a “do nothing” resource and can be used for validating API invocation credentials, performance analysis, and API availability monitoring.

Subscription-Based Shareable API Keys
Navarch is designed for use by enterprise applications, not human users. Moreover, Navarch is required to support the enterprise use cases in which the same application artifact of a project (e.g., a software package, a web application server, a smartphone app, etc.) need be configured with deployment-dependent API invocation credentials. Thus, common private user, account, application, or service API key approach is unsatisfactory in terms of necessary management complexity and cost increase for shared resources/data with sufficient security assurances.

Navarch employs subscription-based shareable API keys to satisfy the requirements effectively and efficiently. An enterprise-compliant Internet-scale realization of it has been deployed in production use via enterprise microservices.

An enterprise IAM microservice (e.g., IBMid) is used to register and authenticate qualified human users of Navarch, each of whom can play the role of Business Administrator, Application Developer, Data Scientist, and/or Service Developer. As Business Administrator, a registered human user can subscribe to a Navarch microservice via an enterprise API services catalog (e.g., IBM APIe). The subscription onboarding process is managed by an enterprise subscription and subscriber management (SSM) service, which supports self-service subscription and subscriber management.

API key lifecycle management (including key creation, access, revocation, deletion, and credential re-generation) and API gateway management capabilities are provided by an enterprise API management (APIM) microservice (e.g., IBM Papillon), and are consumed by the SSM microservice to provision the initial API key to the subscription owner at the end of the subscription provisioning process.

A Subscription Extractor microservice receives SSM subscription updates and saves the relations among subscriptions, subscription API keys, and subscribers into the Cache microservice (e.g., Redis microservice). Via those two microservices, the Requester Handler microservice composes the SSM’s subscription management capabilities and the APIM’s subscriber id and API key validation capabilities to determine the API invocation context for a specific Navarch invocation. In GDPR terms, personal data storage and processing are beyond the scope of APIM, Subscription Extractor, Cache, and Requester Handler. Navarch internal ids are used to fulfill, track, and log all API service requests.

Design of RESTful Enterprise Microservices
A RESTful microservice can be realized by a web application running on a laptop with an HTTP interface. Novel algorithms can be demonstrated by this approach, though making the functional capabilities consumable as enterprise-compliant scalable and composable API services with assured nonfunctional properties requires a lot of effort.

Our six-dimensional approach to designing individually administered composable RESTful enterprise microservices comprises algorithms, models, and/or data artifacts:

Consumer Services: This design dimension focuses on API-enabled as-a-service delivery of functional capabilities to the target consumers with necessary nonfunctional assurances. The service scope can be material discovery, graph analytics, forecasting, etc.
Partner Services: This design dimension considers public/private third-party services that can be integral components of the overall delivery. Sample candidates include cloud object storage services, NOSQL services, pub/sub messaging services, in-memory data structure services, learned-model-based inferencing services, etc.
Hosting Services: This design dimension considers the dependent computing infrastructure and runtime environment in which the microservice code runs. Examples are Kubernetes container clusters (on-premise or cloud-based), Cloud Foundry runtime environments, GPU-equipped servers (virtual or bare metal), high-performance computing systems, etc.
BSS: Business support capabilities are essential to the delivery of enterprise microservices, though they are nonfunctional. These capabilities are costly to create from scratch, just in terms of the non-technical skills and efforts required in possessing them. BSS microservices in the Navarch fabric include external/internal API service catalogs, SSMs, API key management, metering, etc. Compared with the API usage metering in terms of the number of invocations, Navarch can provide auditable fine-grained accounting records with subscription id in terms of completed request fulfillment jobs.
OSS: This design dimension regards acquiring necessary enterprise IT service management capabilities, e.g., external/internal subscriber IAM, workflow execution management, service availability/performance monitoring, policy-based autoscaling, housekeeping, etc.
DevOps Services: This design dimension aims to continuously improve the target RESTful service in an agile, automated, and timely manner by adopting the state-of-the-art continuous integration and continuous delivery (CI/CD) technologies. DevOps microservices in use for the Navarch fabric core include GitHub Enterprise, IBM Cloud container registry and DevOps services, and enterprise Artifactory, Jenkins, and Travis.
Microservices Transformation: An Example
This section presents our experiences with transforming the standalone Python tool AMD into composable enterprise microservices atop a hybrid multicloud. Consumption of the capabilities can be managed under the self-service model by enterprise external/internal subscribers. The contents also exemplify how the Navarch microservices fabric facilitates creating, managing, and improving enterprise API services.

AMD Overview: AI-Accelerated Material Discovery
AI technologies are being exploited in all industries and providing new value creation scenarios. Due to the nature of the unexplored universe of potential materials, material discovery is regarded as one of the high-value yet challenging use cases that require infusing advances in chemistry with the power of machine learning algorithms. Generative model for material discovery is a crucial part of the discovery process.

The AMD tool enables its users to accelerate their respective processes of designing brand new molecular structures that satisfy certain molecule properties (e.g., melting temperature). A dataset-based unit of work generated by the tool can be classified as data transfer, supervised machine learning, model-based inference, non-linear optimization, generative model, and report generation.

The AMD exploitation framework includes metadata for 1,000 molecules sourced from the QM9 (Quantum Machine 9) dataset, including SMILES formatted molecule structure with the associated physical properties for each of the molecules. Two properties are selected to be the target properties: -0.25 for HOMO and 0.08 for LUMO. After the molecule dataset is imported into the tool, a fingerprint for each of the molecules can be generated as a list of feature vectors created in terms of, e.g., number of heavy atoms, number of rings, occurrence of sub-structure, etc.

The feature search step estimates feature vector for the target molecule properties as a first step of the inverse problem-solving of the material discovery process. Given the non-linearity and complexity of the required feature vector estimate model, candidate feature vectors are searched out by particle swarm optimization with a penalty term for design constraint violations. A variation of McKay’s canonical construction path algorithm is employed accordingly.

The structure generation step uses the generative model technology to discover promising molecule structure candidates that would satisfy the given molecule property requirements. Every molecule is modeled as a graph in this step. Via the searched-out feature vector created in the previous step, the discovery process starts with a single atom (vertex) and keeps adding new vertices and edges to it in a depth-first manner. The process is monitored in terms of isomorphism, which judges the molecule’s growth.

OpenAPI Specification Driven Design
Before the enterprise microservice transformation effort started, AMD capabilities could be consumed from within a standalone Python application or a Jupyter notebook hosted by a managed AMD-embedded Jupyter server.

The first step of our transforming the AMD tool into composable enterprise microservices is creating the REST resource model and composing OpenAPI specification for the AMD business microservices.

In REST terms, Navarch’s root resource collections are common to all Navarch clients and are included as part of AMD REST API design. Resource collection [/collections] is extended with support for a new data file type allowing AMD dataset injection via a URL or an S3 object.

New REST resource collections are created under [/amd] in terms of the capabilities of the other functional modules of AMD, namely feature encoding, property prediction, feature search, and structure generation. A new reporting resource collection is used to enable reviewing and saving the data associated with those resources in various MIME formats (e.g., “text/csv”, “application/json”, “image/png”, etc.).

This REST specification-driven approach codifies our integrated data model and operations design for the identified business and IT microservices and drives our downstream integration development and DevOps tasks. The YAML-formatted specifications serve as the authoritative source for publishing business microservices APIs at enterprise external/internal API service catalogs and API gateways as well as for creating a common programming framework for implementing business/IT microservices. This specification-driven approach is different from those that embed operation-specific fragments of REST specification in the source code and generate OpenAPI documents by extracting the annotations via a programming language-specific tool. It is usually uneasy to consume the generated documents due to poor contents for REST resource models and data schema.

Data-Oriented Analysis and Design Refinement
Aligned with the REST architecture design style, data-oriented design review and refinement were performed. We noticed that all data processing and data-driven machine learning operations of AMD are performed in the context of a specific molecule set (or molset). Lifespan of a feature or a model resource must be the same as that of the dependent molset resource. The identified dependencies resulted in refining our initial OpenAPI specification, common resource enhancements, and NoSQL database design for AMD. Moreover, we concluded that the REST update operation was not needed for those aforementioned [/amd] resources, i.e., the resources can be read-only after they are created. This architecture design decision not only reduced implementation complexity, but also facilitated employing caching and replication-based performance and availability enhancement techniques when fulfilling [/amd] invocation requests.

Plugin Based Extensions to Navarch Fabric
From the viewpoint of a capability provider, the Navarch microservices fabric provides enterprise-compliant external and/or internal RESTful service interfaces for its API clients with, among other capabilities, request history logging, self-managing scalable and resilient support for monitoring asynchronous service requests, and hybrid multicloud based data transfer and/or transformation. The fabric’s plugin framework enabled us to add AMD support in the fabric with no need to create new intermediary servers. The plugins used for extending the Navarch fabric for AMD regard service request validation, security/firewall zone accommodation for the requesting client, data transfer under the model of call-by-value, and periodical polling the AMD IT microservice in use on job completion status. Call-by-value model is used for transferring data into Navarch such that changes to the source data after request receiving acknowledge will not affect the fulfillment of the committed request.

IT Microservice Design and Realization
From the viewpoint of Navarch microservices fabric, API service specification and endpoints of capability providing microservices need to be registered with Navarch. Functional id-based basic auth can be used by the IT microservices to authorize Navarch intermediary microservices’ invocations. For a specific asynchronously fulfilled AMD client request, the associated Navarch job id, resource id, and request contents (formatted per the business microservice API specification) are sent to the target AMD IT microservice with input and output data transfer instructions. Navarch provides a common means of delivering request processing results to the client applications via signed temporary URLs or client-provided S3 buckets (with write access credentials for use by Navarch). Capability providing microservices can be oblivious of the details.

Container technology is used for realizing the AMD IT microservices, which are deployed in public and private Kubernetes clusters via enterprise GitHub, DevOps pipelines, and container image repositories. The AMD Python package was extended with a file system-based AMD object caching mechanism and a flask framework-based REST interface. The container exemplifies a Navarch-server integration motif.

Performance Evaluations
This section provides comparative performance analyses of Navarch’s approach to creating composable enterprise computing services. Multitenant production environments were used to gather reported performance measures. Since exclusive use of the networked environments was impossible, measured minimum elapse times are used without loss of generality. All servers used were not optimized for our workloads. Autoscaling performance was not measured.

Single-container Kubernetes pods are used to run the AMD container image, each of which requested to have 1 core and 2 GB RAM. The Jupyter server used for gathering AMD Jupyter performance measures is a shared virtual server configured with 8 cores and 8 GB RAM. One more virtual server with 32 core and 32 GB RAM is used in the comparisons. All servers use Intel Xeon processors.

API Authentication & Authorization Overhead
Compared with the common private key (or token) based approach to authenticating and authorizing API invocations, Navarch supports subscription-based sharing of API keys (as well as data and other computing resources). Subscription id is determined per the API key and subscriber id in use. Secret of API key or password of subscriber id can be optional per service-specific offering manager’s decisions.

Moreover, per GDPR requirements, Navarch request processing frontend maps a client-facing subscriber id into a Navarch internal id for the rest of Navarch microservices. Renaming a subscriber id, for example, has no impact on the Navarch fabric except the AIM and SSM microservices.

The elapse time for completing a “GET /noop” operation through the Internet is used as the performance baseline for fulfilling all Navarch service requests since Navarch qualifies invocation credentials and sets API invocation context for all received requests, including “GET /noop” requests. The measured minimum elapse time for it is 117 msecs.

During that period of time, APIM (1) logs the API invocation request, (2) enforces API invocation throttling policy, (3) validate subscriber id credentials, and (4) validate API key credentials, etc. Navarch Request Handler performs (1) subscriber id to Navarch internal id conversion, (2) subscription id discovery, (3) subscription-based authorization and entitlement per the subscriber internal id and API key in use, (4) request metadata enrichment, etc. The measured minimum time for completing those tasks is 11 msec. Variations in the elapse time for completing those tasks were caused mainly by inter-microservice communication delay between the Request Handler and the Cache (implemented by a commercial Redis microservice). Overall, the performance overhead incurred for supporting subscription-based shared API keys atop APIM’s API key validation mechanism is insignificant.

Comparative Performance Analyses
Browser-based consumption of AMD Jupyter server capabilities starts with establishing a private stateful session with the server via user credentials. The system falls short in supporting the aforementioned enterprise requirements, though the Jupyter browser provides material design scientists an integrated development environment. For example, tasks defined in a Jupyter notebook cell cannot run in parallel. Allocation of entitled server resources cannot adapt to changing workload well in terms of task profiles.

With reference to the AMD exploitation framework, the workloads created for the comparative experimental evaluations include eight feature encoding tasks, two property prediction tasks, and one task of generating ten new promising molecule structure candidates. Related decisions made for conducting the experiments include ensuring going over the entire material discovery process decently and getting comparable results from all the server environments without optimizing any of the request fulfilling systems for the comparative evaluations.

More specifically, a dataset of 1,000 QM9 molecules was created for the experiments. The eight feature encoding tasks added to each of the molecules heavy atom (C, N, O, F, S) count, ring count, aromatic ring count, substructures with 1 and 2 bonds, fingerprint with radius 1, and two feature merge results. Lasso and kernel ridge regression models were used in the step of property prediction. Reflecting the use cases in practice, combinations of features and models were included. The models with the highest cross-validation scores for the two target molecule properties, respectively, were selected for estimating the feature vector for the discovery, followed by generating 10 new molecule structure candidates.

Elapse time measures were gathered from three multitenant production environments: Navarch fabric, AMD Jupyter, and a test server. Navarch fabric includes job completion time measured from within the Navarch fabric, which includes the completion time measured from within AMD Container. Navarch polled the IT microservice in use for job completion status every five seconds. The numbers listed in the “AMD Jupyter” column is measured from within a Jupyter notebook. The test server is used to show that Navarch can exploit heterogeneous microservices that provide the same functional capabilities.

Regarding dataset import, Navarch incurs the overhead of copying client-provided molecule dataset to an S3 object storage under the model of call by value. Although it makes Navarch’s dataset management commitment clear to the client and enables quality-assured data-driven service management and optimization, it increases the one-time cost of importing molecule dataset. For AMD Jupyter and Test Server, the dataset was uploaded to the local file system directly with no need to save an extra copy of the dataset on a remote server.

The eight feature encoding tasks are executed in sequence in AMD Jupyter and Test Server. Compared with the elapse time measures for those two servers, the measures for AMD Container are better than expected in terms of differences in configured virtual CPU and memory capacities. Delay in Navarch Fabric was caused by inter-microservice data copy and container data importing/exporting overhead for completing those tasks. The overhead cannot be eliminated totally due to Navarch’s need to make it data-driven services scalable, resilient, and secure. There is room for significantly optimizing the overall performance, particularly when feature encoding tasks are executed in parallel.

The elapse time measures show that the overhead incurred by Navarch Fabric can be insignificant when data copying overhead is insignificant in terms of workload service time. Moreover, elapse time measures for Test Server suggest that Navarch can employ a policy-based approach to cost-effectively using available heterogeneous microservices.


Conclusions and Future Work
This paper proposes a coherent set of architecture design principles for composing enterprise microservices in large. It also illustrates a hybrid multicloud-based realization of the composable enterprise microservices fabric Navarch. Finally, it illustrates how an AI-accelerated material discovery tool can be systematically and efficiently transformed, via Navarch, into composable enterprise microservices with credible performance measures.

A lot of work has been done in optimizing the design and delivery of distributed applications with the notion of service as a functional (product) abstraction. Much more theoretical and experimental research is needed for the realization and lifecycle optimization of composable enterprise microservices with manageable nonfunctional properties taken into account. Availability, performance, and compliance risk analysis for incrementally deployed enterprise microservices can be scientifically investigated by adopting our enterprise microservice architecture design principles. The principles make measurable functional and nonfunctional properties of microservices and the inter-microservice communications networks among them become essential metadata for enabling design, realization, analysis, and continuously optimization of quality-assured composable enterprise microservices in large.