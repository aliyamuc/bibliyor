SAPPARCHI: an Osmotic Platform to Execute Scalable Applications on Smart City Environments

Arthur Souza, Nélio Cacho, Thais Batista, Rajiv Ranjan

Federal University of Rio Grande do Norte, Natal, Brazil Newcastle University, Newcastle upon Tyne, UK

arthurecassio (@ppgsc.ufrn.br), neliocacho, thais (@dimap.ufrn.br), raj.ranjan (@newcastle.ac.uk)

In the Smart Cities context, a plethora of Middleware Platforms had been proposed to support applications execution and data processing. Despite all the progress already made, the vast majority of solutions have not met the requirements of Applications’ Runtime, Development, and Deployment when related to Scalability. Some studies point out that just 1 of 97 (1%) reported platforms reach this all this set of requirements at the same time. This small number of platforms may be explained by some reasons: Big Data: The huge amount of processed and stored data with various data sources and data types, Multi-domains: many domains involved (Economy, Traffic, Health, Security, Agronomy, etc.), Multiple processing methods like Data Flow, Batch Processing, Services, and Microservices, High Distributed Degree: The use of multiple IoT and BigData tools combined with execution at various computational levels (Edge, Fog, Cloud) leads applications to present a high level of distribution. Aware of those great challenges, we propose Sapparchi, an integrated architectural model for Smart Cities applications that defines multi-processing levels (Edge, Fog, and Cloud). Also, it presents the Sapparchi middleware platform for developing, deploying, and running applications in the smart city environment with an osmotic multi-processing approach that scales applications from Cloud to Edge. Finally, an experimental evaluation exposes the main advantages of adopting Sapparchi.

In the “Smart Cities” are cities that use Cloud Computing, BigData, and Internet of Things as computational skeletons to support solutions built to aimed at the social welfare of their citizens. The applications and solutions produced in the Smart Cities range from simple monitoring of vehicular traffic to Systems for monitoring air quality, such as people prone to heart attacks. It also includes complex systems for monitoring and predicting disasters or assisting police patrols. All this varied set of technologies, domains (security, health, education, transport, housing, etc.), and stakeholders (governments, industries, citizens, etc.) results in an almost infinite universe of choices and opportunities, bringing great challenges for developers of Smart Cities applications.

Middlewares and software platforms have been proposed to fulfill those needs in the context of Smart City’s environment. For instance, some surveys have reported 97 different middlewares or software platforms to accomplish those needs. In contrast to the high number of evaluated solution, only 20 (20.61%) out of 97 have defined an Application Deployment/Runtime model (functional requirements). Besides that, when an Application Deployment/Runtime model focuses on scalability (non-functional), just 01 of those 20 (5%) is selected.

The main reasons for such small number of available solution is directly related to many aspects of smart city applications: Multi-domains: Applications in the context of smart cities seek to support the most varied domains such as Economy, Traffic, Health, Security, Agronomy, etc. In addition to having several stakeholders related to the application contexts, which leads to a high degree of diversity in the solutions, it makes very difficult to delimit generalized models for scalable execution; Processing: Processing methods are also multiple, ranging from simple to complex event processing, data stream processing, batch processing, to the use of machine learning techniques. BigData: The high volume, speed, variability, and volatility of the manipulated data make it even more difficult to run applications, especially in terms of scalability, since the scale-up and scale-down processes must guarantee the consistency and veracity of the data. High Distributed Applications: The use of multiple IoT and BigData tools combined with execution at various computational levels (Edge, Fog, Cloud) leads applications to unveil a high degree of distribution. Sometimes, such application execution makes use of infrastructures of several providers integrating private data-centers and private clouds with public multi-clouds environments. Thus, applications tend to use SOA-based architectural models in combination with platform and middleware services. Therefore, resulting in a complex task of monitoring, managing, and scaling the applications.

All these complexity results in the lack of architectural models for running smart city applications. Consequently, the Computer Service Providers (Cloud Providers, Telephone Operators, Internet Providers) and Application Developers face a great challenge. For example, Service Providers are concerned with: How to measure, charge, deploy, and better execute to use the Computing Infrastructure efficiently. While that for developers is important to know: How to implement, run, manage, scale application components, also, where to store their data, and where to deploy (Cloud, Fog, or Edge). Aware of this gap, this work aims to delimit, implement and evaluate an applications’ execution model that runs over an osmotic platform, called Sapparchi.

Research Contributions: The main contribution of this work is the definition of a Smart Application Architecture platform, named Sapparchi. Sapparchi is a platform to run applications developed by an integrated architectural model driven by osmotic computing and focusing on scalability. Osmotic Computing decomposes applications into microservices and performs dynamic tailoring of them between Edge and Cloud infrastructures. Taking advantage of this idea, Sapparchi was built over four main concepts:

Stream Processing: Sapparchi programming model provides a system of continuous execution of serverless functions (called Actions) directed to workflows (called Tasks). The proposed model follows a similar approach to the one used by OpenWhisk, ThingWorx, Echelon, and Kosmos. Dynamic Deployment Model: The Sapparchi Deployment model defines multi-processing levels, supporting deploy Actions at Edge, Fog, and Cloud. Developers indicate the computational priority level for deploy Actions. Actions’ scale-up and scale-down operations are managed by Sapparchi, taking place within nodes, between nodes of the same level, or between nodes of different levels. Osmotic Execution: Developers/providers can register Actions in static or osmotic execution models. The static actions are executed in their priority levels while the osmotic actions migrate between levels according to definitions of attributes related to the quality of service. Distributed Data Service: Sapparchi also provides a distributed data service between Fog and Cloud to ensure an effective and reliable process of scaling and osmotic migration. Fog’s storage nodes primarily serve Fog and Edge, narrowing the stored entities within their scope. In the Cloud, the storage service aggregates all the entities distributed by the Fog nodes.

SMART CITY APPLICATIONS’ MODELS: Many technological advances that enable solutions for smart cities result from research in the Internet of Things, BigData, and Cloud Computing. Taking this into account, some works have sought to build an architectural model of reference for smart cities. However, these models are generally based on the architectures of platforms or middleware. In other words, an application execution/deployment model that encompasses IoT, BigData, and Cloud Computing is not explicitly defined. The formal definition of the elements that make up a standard architecture for the development, implementation, and execution of applications is paramount for this work.

IoT + Cloud + BigData: Normally, the execution/deployment of applications on Smart City environments are embedded in platforms or middlewares that aggregate IoT application solutions, running it on a cloud. The first architectural model for applications in smart cities is an expression of the understanding in that aggregates the IoT models together with the Cloud. According to the IoT architecture usually comprises three components layers: Sensing layer, this layer includes the various objects of IoT responsible for gauging and providing information about the environment (sensors) and for performing tasks (actuators) that in response to the sensed data, will change the environment in which they are inserted; Network layer, responsible for managing communication between devices and applications; and Application layer, where the applications make use of the data and/or functionalities provided by the devices of the sensing layer.

Applying the architectural concepts of cloud-native applications to the Context of Smart Cities the authors present a generic architecture for smart city solutions deployed on cloud computing platforms. In this way, a layered architecture composed of three levels: Data sources, groups all data sources (physical or logical) operating in smart cities; Data Processing, capture, processing and make available the data from data sources; Application, represents the applications, dashboards, and websites that make up the city’s management portal. When we integrate the IoT and Cloud models, the Sensoring and Network layers are represented by Data Sources, while the processing itself of the Application in the IoT is decomposed into Data Processing and Application in the Cloud.

An architectural model for Big Data solutions is defined and focuses on Stream processing. Conceptually, the essential components of an architecture for processing in BigData are Data Source, Data Ingestion, Data Processing, Data Analytics and Visualization. Data Sources that comprise the various data sources that feed the processing components. Next, Data Ingestion is responsible for cleaning, validating, categorizing, transforming, and grouping the data received. Soon after, Data Store provides storage in a format compatible with Data Processing and Data Analytics. Data Processing performs BigData processing itself, notably the Map/Reduce technique. Data Analytics refers to tools for data analysis, such as statistical analysis, textual analysis, search engines, machine learning techniques. Finally, we have Visualization which comprises the tools for querying and visually manipulating data, as well as administrative tools.

In the context of Smart City, the BigData model integrates architectures that focus on data acquisition from Sensoring layer of IoT. While the Data Ingestion, Processing, Analytics and Visualization are executed on Cloud, being specializations of Data Processing and Application layers. The integration of Cloud, IoT, and BigData models reveals the architectural components that compose applications for Smart Cities. Taking these concepts into account, we present a model that integrates the Cloud, IoT, and BigData models into a consolidated architectural view.

Sensoring - IoT is carried out through a network of geographically dispersed devices throughout the city. Interconnection Layer - IoT and Cloud that represents the communication infrastructure (gateways, mobile devices, protocols, middleware, proxies, etc.) that promotes connectivity from the Sensoring to the other layers. Data Processing - IoT, BigData and Cloud is responsible for receiving, processing, and sent to the sensed data to storage. Data Storage - BigData aggregates the services, devices, and infrastructure responsible for storing all data. Application - IoT, BidData and Cloud encompasses all the services, devices, and infrastructure responsible for the logical processing and presentation of the data available in the Data Store. Finally, the Management layer - BigData and Cloud manages the services that deployed in all other layers.

Having these concepts outlined in our mind, we can identify that the elements directly related to the processing of applications for Smart Cities make up the services of the Data Processing, Data Store and Application layers. In other words, those components make up the main services regarding the logic, presentation, and construction of the information extracted from the city. In summary, the core of processing from applications to Smart Cities are composed of three types of services: Data Service: are the services that capture, ingest and process data from the multiple data sources of Smart Cities; Storage Service: are the services that provide the storage of data produced in Data Services and Application Services; Application Service: are the logical processing, visualization, machine learning, and artificial intelligence services.

Currently, the most accepted architectural development/deployment model for Smart City applications is represented as a processing unit graph (usually DAG type). Each vertex of the graph represents a service, microservice, or serverless function that the application uses. Categorizing those services in Data, Storage and Application tells developers what will be built but does not defines where or how the services should be deployed. Therefore, we defend that some application’s services had an associated computational level (Cloud, Fog, or Edge) for its implementation. When the service is related to more than one level, it characterizes an osmotic service. In other words, we adopt Osmotic Computing to define services that do not have a specific level, fluctuating between Edge to Cloud or vice versa (Osmotic Services).

Osmotic Computing: The vast majority of solutions for Smart Cities deploy their services in the Cloud. With the advent of edge computing and fog computing, new computing resources were added to the infrastructures of Smart Cities, demanding new architectures and components to properly exploit the potential of all levels (Cloud, Fog, or Edge). In this way, several works present container processes (Docker, Linux LXC) as a solution to promote the rapid implementation of diverse services in the different levels of the computational infrastructure of a Smart City.

Despite the significant advances in this area, there is still a gap in the definition of an architecture that integrates the computational levels of Cloud, Fog, and Edge. Going beyond Fog/Edge computing, some authors support the idea that Osmotic Computing can fulfil this gap. Osmotic computing is a new paradigm to support the efficient execution of Internet of Things (IoT) services (microservices) and applications at the network edge by providing increased resource and management capabilities at the edge of the network.

In osmotic computing, applications are decomposed into microservices and perform dynamic tailoring of microservices to exploit the resources from Edge to Cloud infrastructures. Hence, Osmotic computing provides an abstraction referred to as microelements (MELs), encapsulating resources, services, and data. In other words, the services that make up the osmotic application are represented by MicroElements (MELs). The MELS are composed of two types of software components: MicroServices (MS) and MicroData (MD). The MS implements specific functionalities which can be deployed and migrated across different infrastructures, and MicroData (MD) represents a piece of information flowing from and to IoT sensor node and actuator devices. The authors present Osmosis as a platform for osmotic computing in IoT systems. At Osmosis, applications run as a graph of MELs that can migrate between the Cloud or the Edge dynamically following Quality of Services (QoS) parameters.

MELs can be specialized in types for specific levels such as Cloud, Fog, or Edge. The implementation of MELs would occur through Containerization technologies. All MELs that make up osmotic applications must be monitored to report the runtime metrics related to QoS restrictions for the dynamic adjustment of the application. This entire development/deployment process follows a 4-step flow: Decompose Applications into microservices, Perform dynamic tailoring of microservices, Microservices in containers are deployed in Cloud or Edge, Execution of load balanced Microservices. This flow has a circular control that uses the metrics obtained by Monitoring to continuously re-execute steps 2, 3, and 4 promoting the rebalancing of microservices between the Cloud and Edge.

SAPPARCHI: Sapparchi is a platform to run smart city applications developed by an integrated architectural model driven by osmotic computing and focusing on scalability. The Sapparchi construction is based on an integrated architectural model for Smart Cities applications that define multi-processing levels (at the moment can support Edge, Fog, and Cloud) where the services that make up the applications can run in a static or osmotic model.

Programming Model: The Sapparchi programming model provides a system of continuous execution of serverless function workflows, similar to the one used in ThingWorx, Echelon, Concinnity, and Kosmos. Actions are the smallest processing units at Sapparchi. Actions are processing units for data manipulation without direct persistence of entities. The concern in building an Action is to ensure that the behaviour performed by it is fluid and fast, providing and prioritizing the processing with data streams.

The processing flow between Actions occurs by sending Messages. Messages are elements of communication between Actions. Messages are composed of an Action target key and a MessageData. MessageData is a string on JSON-Format. The JSON-Format allows deployment of Action Executors with different technologies, like Javascript or Python. Actually, Sapparchi implementation uses Java.

In addition to the concept of Action, Sapparchi defines the concept of Tasks. Tasks are directed processing flows between Actions. Actions and Tasks model is similar to the ones presented by OpenWhisk. However, in Sapparchi Actions and Tasks are deployed on groups of: Applications, Services, or Microservices.

Application represents an integral set of Actions and Tasks related to a specific solution. Sapparchi’s model also defines that a Microservice is a set of Actions that act only on a specific group of Entities (just one class of Entities). Service is a set of Actions that acts on several types of Entities (various classes of entities). This delimitation between Applications, Services, and Microservices allows a more partitioned deployment model. The execution of Actions can launch Data State changes that will be sent to Sapparchi Data Store service to be properly persisted. The total separation between persistence and processing helps the osmotic execution of Actions. The Osmotic Computation occurs through Actions/Tasks migrations between workers nodes.

Architecture Overview: Architecturally, the Sapparchi middleware platform focuses on executing the Sapparchi programming model in a scalable and highly distributed manner. For this purpose, it defines several components deployed on distributed multi-level nodes that act as managers or workers. Those components illustrated on are colored taking into account the model explained. Sapparchi architecture comprises many components, such as: Resources Catalog, Manager Service, Monitor Service, Executors, Deployment Service, Data Service, and API Services/API Router.

The Monitor Service provides functionalities for monitoring the execution of nodes registered on Sapparchi Manager Node. Deployment Service manages the deployment of Executors, taking into account nodes, actions, and tasks registered on the Resources Catalog. Resource Catalog component stores data that describes nodes, actions, tasks, microservices, and services. Executors are responsible for executing Actions/Tasks implemented at Sapparchi. Deployment Services and Executors leverage Docker infrastructure to run containers on workers nodes. In contrast, the Management Service manages and orchestrates the Actions/Tasks deployment on the workers nodes. The RabbitMQ promotes communication between components. Data Services/Data Sync promotes data persistence with MongoDB and Redis. Finally, API Services/API Router uses Nginx to perform load balancing and request routing between workers nodes.

Parallel and distributed execution: The programming model defined Sapparchi supports the execution of serverless functions in a parallel and distributed manner. The distributed execution of Actions takes place on worker nodes. Each computational level: Cloud, Fog, or Edge has a compatible worker node implementation. This specification occurs through the development of specific Docker images for each level.

Parallelism in the processing a specific requests is supported by a queuing scheme and message consumption performed by Actions Executors. Requests sent to Sapparchi pass through Nginx, which forwards to API Gateway. API Gateway provides an HTTP API that receives requests via HTTP protocol. After this, the API Gateway creates a unique identifier for the request and returns an HTTP 303 (See Other) code. This return indicates in the header the HTTP Get endpoint where the response will be obtained. Then the return is passed on to the request’s client. The client consults the provided endpoint to obtain the response. In this way, the processing of submissions already received does not block the receipt of new ones.

Each incoming request is converted by API Gateway into a Sapparchi Message that will be sent to Action Executors deployed on Workers Nodes. To do so, API Gateway queries the list of Nodes, Actions, and Tasks registered with Sapparchi. This list is obtained and synchronized with the Resources Catalog. Once the endpoint of the next available Works node is obtained, the Message is sent. On Workers nodes, each Action Executor runs as a Messages consumer process. After the Message is processed, the Action Executor registers with the node’s API Router the response referring to the requested ID. Finally, the client that was querying the API Route via Nginx will receive the response.

Deployment Model: Using concepts of Osmotic Computing, Sapparchi implements MELs as serverless functions called Actions. Actions would be the smallest level of granularity of an application’s services. Action groups could be configured and deployed as Microservices (Fog or Cloud) or Services (Cloud), while Applications would be sets of Actions, Microservices, and Services. The data persistence occurs through Data Store services provided by the Sapparchi Platform. Delegating the storage to the Data Store service allows the Actions only concerned about processing that promotes a data stream processing flow.

Actions can be deployed on dedicated or shared Containers or Edge nodes, while Microservices and Services would have dedicated Containers. The granulation of Actions, Microservices, and Services allows the distribution between tiers once an Edge node would not have the computational capacity of a Cloud node.

The choice to use serverless, microservices and services is supported by results present on According to Nastic et al, Serverless computing is an emerging execution model in which user-defined functions are managed by a distributed platform. The benefits of the serverless model become especially evident in the context of cloud and edge computing, as both models aims to mitigate inefficient, error-prone, and costly infrastructure and application. The microservice concept is an architectural style used to building large-scale distributed applications composed of small, interconnected components to support scalability, evolvability, maintainability, and modularity.

Serverless on Edge and Microservice in Fog seek to meet the main non-functional requirements of Smart Cities applications. Scalability takes both technologies to increase or decrease the number of instances, promoting direct horizontal Scalability. For Security and Privacy, serverless enables more control because all functions deployed will be managed by the platform that provides security mechanisms like proxies-API, route-firewalls, federation, etc. The download of a new version of the entire microservice will be necessary at some point of time. This necessity can create some security holes. To decrease this risk, we argue that the use of microservices will be on charge of Fog or Cloud levels, where there is greater computational power to be employed in the security infrastructure.

EVALUATION: Automotive traffic management in cities is a major concern for both government officials, and citizens. For example, within the scenario of vehicular traffic management in urban centers, the provision and efficient occupation of parking spaces is a common problem to be solved. A survey by INRIX Research found that Americans pay a cost of U$ 73 billion annually in searches for parking spaces.

Smart Parking Application: The Smart Parking application searches for real-time mapping of parking spaces available in a city. A driver accesses the Smart Parking application to know the best places available according to his personal preferences. The main use case follows the flow: the driver travels by a road, The Smart Parking application is notified of the position of the driver, and searches for possible available positions, Smart Parking alerts the driver the available vacancies. With this scenario, three components can implements Smart Parking Application, namely: User Service, Selection Service and Parking Service.

Parking Service uses parking sensors to continuously monitor vacancy status. These vacancies can be in public or private space. User Service is responsible for storing user data (parking preferences, costs, and history) as well as for providing system communication with the user. User interaction can occur via an application deployed on his/her smartphone. Selection Service continuously receives user’s application job requisitions. The incoming requisitions are processed through a selection of algorithms that continuously queries the Parking Service and User Service to check the status of the vacancies and get user’s preferences. Once the best free vacancies are defined the SS notifies the user’s application.

Although it is simple to understand this application, the number of competing users, as well as the number of spaces to be monitored, can lead to a large computational infrastructure to support Smart Parking. For example, in 2011, a post on nyc.streetsblog.org estimates that there were 3.4 million to 4.4 million parking spaces in New York City’s streets. Having this in mind clarifies the challenges faced by stakeholders in solutions for smart cities. Among the various implementation a Smart Parking application can have, we have implemented the same application using three different approaches, namely: Fiware, Microservice, and Sapparchi.

Fiware is a generic, extensible platform able to cope with essential requirements in smart cities. A central element of Fiware architecture is the Orion Context Broker. Orion Context Broker is a context-aware publish-subscribe broker responsible for sending and receiving context data from/to applications using Fiware. The Smart Parking application, when developed using Fiware, aggregates all data on Orion. The Parking Service continuously receives the data from spots devices to inform the vacancies status to Orion. The User Service receives the Driver’s geographic position and passes it to Orion. The Selection Service queries only the Orion to get all necessary data to process the Driver’s request.

The Microservice approach follows the design principles of Microservice technique. In this way, data regarding a user is saved on his database, while the Parking service manages and stores the parking database. The parking Service stores the data regarding the status of the vacancies, while the User Service deals with all user data. The Selection Service accesses the data by referring to Parking and User services, creating a service graph.

The Smart Parking implementation using Sapparchi model has the same three services. The difference is on how the developer would build these services, that is by performing the composition of Actions. For example, the Parking Service is composed of two Actions: Parking Spot Monitor and Get Free Spots. Parking Spot Monitor runs at the Edge checking the status of the sensed vacancies. Once statuses change, this data is sent to DataSync, a Sapparchi component deployed on Fog. Get Free Spots performs queries for vacancies available close to a location. User Service is composed of two other Actions: Save Preferences and Get Preferences. Save Preferences performs operations to persist the driver’s preference and history data on Sapparchi Data Service. Get Preferences would return driver preferences. Finally, the Selection Service would be composed of a Task (Selection Vacancies Task) that integrates the Actions Get Preferences, Get Free Spots, and Get Best Spots. The action Get Best Spots runs the algorithm for selecting vacancies. For instance, the Selection Vacancies Task indicates that processing starts on Action GetPreferences, goes to Action GetFreeSpots, and finish on Action GetBestSpots.

Experiment: The main objective of this evaluation is to assess the behavior of the three implementations (Fiware, Microservice and Sapparchi) regarding the parameters of throughput and latency time in the scalability scenario for osmotic services. Osmotic services would be those that migrate at the various computational levels. In the Smart Parking example, the service most closely related to this categorization would be the Selection Service. The Selection Service depends on the Parking and User services. The Parking Service must be close to the Edge as it receives data from sensors. The User Service needs to receive data from all drivers, as well as allow this data to be easily accessible in various locations in the city, being more related to the Cloud. Finally, the Selection Service, which is a necessary service when drivers are looking for vacancies, can be deployed on Fog or Cloud. On Fog when there is low demand and on the Cloud when there is high demand.

Having these premises defined, the three approaches (Fiware, Microservice, and Sappparchi) were deployed, according to the schematic presentation. Fiware services and Microservice were built as web applications written in Java using the Spring framework, version 2.2.4.RELEASE. The implementation of these services used Docker containers running OpenJDK 18 images together with Fiware Orion (3.6.0) and MySQL (5.7) on Microservice. In the Sappachi model, the GetPreferences, GetFreeSpots, and GetBestSpots actions were implemented in Java and executed on the Sapparchi Middleware Platform. Currently, Sapparchi has being developed in Java, using the Spring framework (2.2.4.RELEASE) as a basis for executing its components, while using MongoDB(4.4) and Redis (alpine) in the Data Store service. The communication and synchronization of the components use RabbitMQ (3.7) while the API services uses Nginx as an HTTP gateway and load balance. The deployment of Sapparchi Executors Nodes (Cloud, Fog) also made use of Docker containers with OpenJDK 18. To Edge level, we have used Docker Hub images of: hypriot/rpi-java and hypriot/rpi-mysql.

The infrastructure configured for the experiment consisted at: in the Cloud level of virtual machines on Amazon EC2, Oregon region, with t2.small configuration (1 vCPU, 2 GB RAM); at FOG level in virtual machine (2 vCPU, 2 GB); and at Edge level in Raspberry PI 1 (Model B, 700 Mhz and 512 MB). The Fog and Edge nodes was located on a research lab and access the Amazon Cloud through public internet provider optic fiber link with 200 MB of bandwidth. The simulated workload was produced via Apache JMeter running in the Amazon Cloud on machine t2.medium (2 vCPU, 4 RAM). The simulated load consisted of 250 threads sending requests over a period of 5 minutes, of which the initial 30 seconds served as warm-up and thread creation. Requests were sent to the Selection service in test cases: Cloud only, Fog only and Cloud together with Fog.

Results: The load tests of the experiment were performed between three days in 2022. The results obtained for each test case are presented. Sapparchi showed the best result for the three scenarios, namely: 46708, 43267, and 78715 requests. Fiware’s Orion-based solution obtained the second best result: 32575, 22728, 48428. Finally, Microservice obtained: 25149, 21070, 16282.

The results obtained for processing rate are shown. In the execution of T1, Microservice obtained 83.1 reqs/sec; Fiware 124.11 reqs/sec; and Sapparchi 148.3 reqs/sec. For T2, Microservice had 69.82; Fiware scored 72.53; while Sapparchi reached 136.51. Finally, in Q3, Microservice decreased to 52.24; Fiware scored 159.92; Sapparchi rose to 243.09.

The prolonged execution of T1, T2 and T3 allowed the construction of a graph representing the dispersion of the latency time of requests between the three approaches. The median latency times for Fiware were: 1.708, 2.643, and 2.646 seconds. The median results for Microservice were: 2.726, 3.042, and 7.533 seconds. Sapparchi got: 3.087 seconds, 3.372, and 1.824 seconds.

Discussion: Sapparchi performed better in terms of the total number of processed requests. Sapparchi model prioritizes data stream processing by Actions. Allied to this, the incoming requests are queued and consumed by the Actions executors in parallel once each Action is stateless. The inferior result of Microservice is explained by the fact that every request made needs to go to the Edge level to consult the Parking Service. It is important to note that Sapparchi was the only solution that presented errors on all tests. This occurs because the API Gateway strategy of Sapparchi uses HTTP redirection (HTTP 303 See Other) between request submission and response. When those redirections happen many times the JMeter cancels the request.

The same explanation regarding Sapparchi’s processing parallelism can be extended to clarify the optimal result for throughput. Mainly, in the T3 case (osmotic scalability), Sapparchi presented the best distribution and efficiency of the analysed approaches. While Sapparchi and Fiware showed a similar behavior when increasing the rate between T1 and T3, and decreasing T2, Microservice had a decreasing rate from T1 to T3. This behavior occurs due to the increased load on the Parking Service in T3, the Cloud and Fog Selection Service instances compete with each other for accessing the Parking Service.

The best median results for latency time obtained by Fiware may be due to the requests being originated in the Cloud and Fiware centralizes its data processing in Orion. Microservice’s behavior in T3 is easily explained by the competition between the Cloud and Fog tiers over the Edge tier, greatly increasing the wait time. When evaluating Sapparchi, it is clear that the cost of parallel processing is increasing in overhead in the response time of requests. Another point of interest is the virtually equal values between Cloud and Fog. This result stems from the fact that the increase in the processing time of a request in the Actions models running in the Cloud balances the level of difference between the Cloud and Fog latency times. Finally, in the T3 scenario, Sapparchi presents the best result since it effectively distributes the workload between the Cloud and Fog, reducing the latency time in general.

RELATED WORK: This work focus on scalability regarding to deploying application to smart city scenarios. Application Development delimits platforms that offer tools for developing solutions to problems that involve the heterogeneity of IoT environments, ranging from sensors to actuators. Application Deployment/runtime deals with managing the execution of their applications, facilitating the deployment and integration of smart city applications. Some of those platforms provide a complete environment for developers to deploy their applications while other platforms offer an execution run-time service.

ThingWorx is an IoT platform and offers a data driven decision making Private Cloud Platform. The computation execution within the platform occurs via the WorkFlows that define a directed graph of Connectors. A connector is a collection of predefined actions, triggers, authorizations, and connections, which can be configured for use in workflows to interact with external systems or perform a specific task. The Actions are an individual step in a workflow that takes input data and performs a specific task while the a trigger is a specialized action that you can configure on the start of a workflow. The Sapparchi model of programming in Actions and Tasks is very similar to ThingWorx. However, it is important to emphasize that Sapparchi allows the implementation and migration of Actions between Cloud, Fog and Edge while ThingWorx focus the processing on Cloud.

In a different approach closer to Edge, Echelon’s IzoT Platform is an IP-enabled, multi-protocol, multi-media control and communications platform specifically architected for the Industrial Internet of Things (IIoT). The Edge programming occurs through SmartIoTServer. SmartIoTServer performs web page hosting, Node-Red processing flows, etc. Computing at the edge takes place through the processing of DataPoints. DataPoints are abstractions that can represent a simple value or a set of values, which can be consulted on the IzoT network. The concept of DataPoints is similar to Sapparchi’s distributed storage model although it only focuses on the Edge level.

Kosmos is an IoT platform that seeks to foster the engagement of the ecosystem that makes up the smart city through a dashboard for creating and sharing service compositions without explicit coding. Kosmos’ visual programming allows multiple actors to participate in creating solutions for the city. Architecturally, it can be seen as a platform for Cloud and Edge levels. At Edge is the Kosmos Gateway that allows the registration of devices linked to the sensory network. In practice, Kosmos Gateway is a Raspberry that runs software for registering, managing, and processing devices. The programming model at Edge occurs by defining rules for alerts and triggers for when any condition is reported by the sensors. Unlike Kosmos, Sapparchi handles Fog-level execution between Cloud and Edge. Furthermore, it adds the concepts of osmotic computing promoting osmotic scalability of services.

The authors present FogFlow, a framework which provides a standard-based programming model for IoT services for Smart Cities that run over cloud and edges. Like as Sapparchi on Flog Flow the applications can be split in tasks that can will be executed in docker’s containers on edge devices. In contrast to Sapparchi, FogFlow does not support migrating edge tasks to Cloud.

Our proposal builds upon many of these works but, to the best of our knowledge, is the first one to leverage osmotic computing concepts in order to promote scalability of smart city applications deployed at Cloud, Fog and Edge levels.

CONCLUSIONS: In this work we present Sapparchi. Sapparchi is a middleware platform for deploying, running, and scaling applications for smart cities. It defines a programming model based on data stream processing that allows the composition of serverless functions in microservices and services. It enables the deployment and execution of services at the Cloud, Fog, and Edge levels in an integrated way that allows osmotic execution. Although the Sapparchi platform has not been fully implemented, an initial implementation that focused on osmotic scalability was presented and evaluated in order to prove the concepts and definitions presented by the Sapparchi model. The results of the experimental evaluation corroborate the effectiveness of the Sapparchi programming model mainly in terms of scalability between levels of Cloud and Fog. Future works will seek to implement all Sapparchi components related to self-managed scalability and live action migration.